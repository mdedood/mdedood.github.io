{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4:  Exponential decay\n",
    "\n",
    "The file [Geiger.dat](Geiger.dat) contains data from a Geiger counter used to investigate radioactive decay from an unknown source. The datafile contains the number of counts during one minute measured every hour. In this exercise you may assume that the noise or error in the count rate is a random or Poissonian process. In this case the error (standard deviation) on the number of counts $\\bar{n}$ is given by the square root of the number of counts, i.e. $\\bar{n} \\pm \\sqrt{\\bar{n}}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (hr) \t Counts/min\n",
      "\n",
      "0 \t \t 997\n",
      "1 \t \t 520\n",
      "2 \t \t 265\n",
      "3 \t \t 127\n",
      "4 \t \t 70\n",
      "5 \t \t 35\n",
      "6 \t \t 16\n",
      "7 \t \t 7\n",
      "8 \t \t 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t, n = np.loadtxt('Geiger.dat', delimiter=',', skiprows=5, usecols=(0, 1), unpack=True)\n",
    "\n",
    "print('Time (hr) \\t Counts/min\\n')\n",
    "for i in range(len(t)):\n",
    "    print('%d \\t \\t %d' % (t[i],n[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radioactive decay is described by exponential decay given by\n",
    "$$n(t) = n(0) \\exp{\\left(-\\frac{t}{\\tau}\\right)}$$\n",
    "\n",
    "### a) Ignore the error bars. Fit an exponential decay to the data to determine the time constant $\\tau$. Make a plot of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential decay is best fit on a semi-logarithmic scale. This helps to visualize if the data is truly exponential.\n",
    "\n",
    "### b) Ignore the error bars. Fit the logarithm of the measured count rates $\\ln(n(t)$ to a straight line and determine the time constant $\\tau$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Compare the values of $\\tau$ found using the two methods in a) and b). Do you find a difference? If so, explain the origin of this differnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Calculate the error bar for each of the count rates and repeat the exponential and linear fit by taking the error bar into account in the fit. You will need to calculate the error in $ln(n)$.  Do you find the same value for $\\tau$ using both ways to fit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Calculate the normalized value of $\\chi^2$. What can you say about the experimental data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
